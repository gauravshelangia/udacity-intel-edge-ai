{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_x42qonj"
   },
   "source": [
    "# Exercise: VPU and the DevCloud\n",
    "\n",
    "Now that we've walked through the process of requesting a CPU with a VPU (Intel® NCS2) on Intel's DevCloud and loading a model on the Intel® NCS2, you will have the opportunity to do this yourself with the addition of running inference on an image using both a CPU and IGPU.\n",
    "\n",
    "In this exercise, you will do the following:\n",
    "1. Write a Python script to load a model and run inference 100 times on a device on Intel's DevCloud.\n",
    "    * Calculate the time it takes to load the model.\n",
    "    * Calculate the time it takes to run inference 100 times.\n",
    "2. Write a shell script to submit a job to Intel's DevCloud.\n",
    "3. Submit a job using `qsub` on an **IEI Tank-870** edge node, run `liveQStat` to view the status of your submitted jobs, then retrieve and view the results from your job.\n",
    "    * One job using `CPU` as the device.\n",
    "    * One job using `GPU` as the device.\n",
    "    * One job using `VPU` as the device.\n",
    "4. Plot and compare the results using bar graphs with `matplotlib` for the following metrics:\n",
    "    * Model Loading Time\n",
    "    * Inference Time\n",
    "    * Frames Per Second (FPS)\n",
    "\n",
    "Click the **Exercise Overview** button below for a demonstration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_8egtpc8"
   },
   "source": [
    "<span class=\"graffiti-highlight graffiti-id_8egtpc8-id_0itthyg\"><i></i><button>Exercise Overview</button></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_66qiqtf"
   },
   "source": [
    "#### IMPORTANT: Set up paths so we can run Dev Cloud utilities\n",
    "You *must* run this every time you enter a Workspace session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_lf27aul"
   },
   "outputs": [],
   "source": [
    "%env PATH=/opt/conda/bin:/opt/spark-2.4.3-bin-hadoop2.7/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/intel_devcloud_support\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('/opt/intel_devcloud_support'))\n",
    "sys.path.insert(0, os.path.abspath('/opt/intel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_lf27aul"
   },
   "outputs": [],
   "source": [
    "%env PATH=/opt/conda/bin:/opt/spark-2.4.3-bin-hadoop2.7/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/intel_devcloud_support\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('/opt/intel_devcloud_support'))\n",
    "sys.path.insert(0, os.path.abspath('/opt/intel'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_s7we0gs"
   },
   "source": [
    "## The Model\n",
    "\n",
    "We will be using the `vehicle-license-plate-detection-barrier-0106` model for this exercise.\n",
    "\n",
    "Remember to use the appropriate model precisions for each device:\n",
    "\n",
    "* CPU - `FP32`\n",
    "* IGPU - `FP16`\n",
    "* VPU - `FP16`\n",
    "\n",
    "The model has already been downloaded for you in the `/data/models/intel` directory on Intel's DevCloud.\n",
    "\n",
    "We will be running inference on an image of a car. The path to the image is `/data/resources/car.png`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_5wn0v72"
   },
   "source": [
    "# Step 1: Creating a Python Script\n",
    "\n",
    "The first step is to create a Python script that you can use to load the model and perform inference. We'll use the `%%writefile` magic to create a Python file called `inference_on_device.py`. In the next cell, you will need to complete the `TODO` items for this Python script.\n",
    "\n",
    "`TODO` items:\n",
    "\n",
    "1. Load the model\n",
    "\n",
    "2. Get the name of the input node\n",
    "\n",
    "3. Prepare the model for inference (create an input dictionary)\n",
    "\n",
    "4. Run inference 100 times in a loop\n",
    "\n",
    "If you get stuck, you can click on the **Show Solution** button below for a walkthrough with the solution code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_h3z21kd"
   },
   "outputs": [],
   "source": [
    "%%writefile inference_on_device.py\n",
    "\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from openvino.inference_engine import IENetwork\n",
    "from openvino.inference_engine import IECore\n",
    "import argparse\n",
    "\n",
    "def main(args):\n",
    "    model=args.model_path\n",
    "    model_weights=model+'.bin'\n",
    "    model_structure=model+'.xml'\n",
    "    \n",
    "    start=time.time()\n",
    "    model=IENetwork(model_structure, model_weights)\n",
    "\n",
    "    core = IECore()\n",
    "    net = core.load_network(network=model, device_name=args.device, num_requests=1)\n",
    "    load_time=time.time()-start\n",
    "    print(f\"Time taken to load model = {load_time} seconds\")\n",
    "    \n",
    "    # Get the name of the input node\n",
    "    input_name=next(iter(model.inputs))\n",
    "\n",
    "    # Reading and Preprocessing Image\n",
    "    input_img=cv2.imread('/data/resources/car.png')\n",
    "    input_img=cv2.resize(input_img, (300,300), interpolation = cv2.INTER_AREA)\n",
    "    input_img=np.moveaxis(input_img, -1, 0)\n",
    "\n",
    "    # Running Inference in a loop on the same image\n",
    "    input_dict={input_name:input_img}\n",
    "\n",
    "    start=time.time()\n",
    "    for _ in range(100):\n",
    "        net.infer(input_dict)\n",
    "    \n",
    "    inference_time=time.time()-start\n",
    "    fps=100/inference_time\n",
    "    \n",
    "    print(f\"Time Taken to run 100 Inference is = {inference_time} seconds\")\n",
    "    \n",
    "    with open(f\"/output/{args.path}.txt\", \"w\") as f:\n",
    "        f.write(str(load_time)+'\\n')\n",
    "        f.write(str(inference_time)+'\\n')\n",
    "        f.write(str(fps)+'\\n')\n",
    "\n",
    "if __name__=='__main__':\n",
    "    parser=argparse.ArgumentParser()\n",
    "    parser.add_argument('--model_path', required=True)\n",
    "    parser.add_argument('--device', default=None)\n",
    "    parser.add_argument('--path', default=None)\n",
    "    \n",
    "    args=parser.parse_args() \n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_l7v4f6u"
   },
   "source": [
    "<span class=\"graffiti-highlight graffiti-id_l7v4f6u-id_oeichcd\"><i></i><button>Hide Solution</button></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_oeichcd"
   },
   "outputs": [],
   "source": [
    "%%writefile inference_on_device.py\n",
    "\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from openvino.inference_engine import IENetwork\n",
    "from openvino.inference_engine import IECore\n",
    "import argparse\n",
    "\n",
    "def main(args):\n",
    "    model=args.model_path\n",
    "    model_weights=model+'.bin'\n",
    "    model_structure=model+'.xml'\n",
    "    \n",
    "    start=time.time()\n",
    "    model=IENetwork(model_structure, model_weights)\n",
    "\n",
    "    core = IECore()\n",
    "    net = core.load_network(network=model, device_name=args.device, num_requests=1)\n",
    "    load_time=time.time()-start\n",
    "    print(f\"Time taken to load model = {load_time} seconds\")\n",
    "    \n",
    "    # Get the name of the input node\n",
    "    input_name=next(iter(model.inputs))\n",
    "\n",
    "    # Reading and Preprocessing Image\n",
    "    input_img=cv2.imread('/data/resources/car.png')\n",
    "    input_img=cv2.resize(input_img, (300,300), interpolation = cv2.INTER_AREA)\n",
    "    input_img=np.moveaxis(input_img, -1, 0)\n",
    "\n",
    "    # Running Inference in a loop on the same image\n",
    "    input_dict={input_name:input_img}\n",
    "\n",
    "    start=time.time()\n",
    "    for _ in range(100):\n",
    "        net.infer(input_dict)\n",
    "    \n",
    "    inference_time=time.time()-start\n",
    "    fps=100/inference_time\n",
    "    \n",
    "    print(f\"Time Taken to run 100 Inference is = {inference_time} seconds\")\n",
    "    \n",
    "    with open(f\"/output/{args.path}.txt\", \"w\") as f:\n",
    "        f.write(str(load_time)+'\\n')\n",
    "        f.write(str(inference_time)+'\\n')\n",
    "        f.write(str(fps)+'\\n')\n",
    "\n",
    "if __name__=='__main__':\n",
    "    parser=argparse.ArgumentParser()\n",
    "    parser.add_argument('--model_path', required=True)\n",
    "    parser.add_argument('--device', default=None)\n",
    "    parser.add_argument('--path', default=None)\n",
    "    \n",
    "    args=parser.parse_args() \n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_2juc6uh"
   },
   "source": [
    "## Step 2: Creating a Job Submission Script\n",
    "\n",
    "To submit a job to the DevCloud, you'll need to create a shell script. Similar to the Python script above, we'll use the `%%writefile` magic command to create a shell script called `inference_model_job.sh`. In the next cell, you will need to complete the `TODO` items for this shell script.\n",
    "\n",
    "`TODO` items:\n",
    "1. Create three variables:\n",
    "    * `DEVICE` - Assign the value as the first argument passed into the shell script.\n",
    "    * `MODELPATH` - Assign the value as the second argument passed into the shell script.\n",
    "    * `SAVEPATH` - Assign the value as the third argument passed into the shell script.\n",
    "2. Call the Python script using the three variable values as the command line argument\n",
    "\n",
    "If you get stuck, you can click on the **Show Solution** button below for a walkthrough with the solution code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_xrzmnou"
   },
   "outputs": [],
   "source": [
    "%%writefile inference_model_job.sh\n",
    "#!/bin/bash\n",
    "\n",
    "exec 1>/output/stdout.log 2>/output/stderr.log\n",
    "\n",
    "mkdir -p /output\n",
    "\n",
    "DEVICE=$1\n",
    "MODELPATH=$2\n",
    "SAVEPATH=$3\n",
    "\n",
    "# Run the load model python script\n",
    "python3 inference_on_device.py  --model_path ${MODELPATH} --device ${DEVICE} --path ${SAVEPATH}\n",
    "\n",
    "cd /output\n",
    "\n",
    "tar zcvf output.tgz *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_muqucn2"
   },
   "source": [
    "<span class=\"graffiti-highlight graffiti-id_muqucn2-id_g84tg5a\"><i></i><button>Show Solution</button></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_2815f6k"
   },
   "source": [
    "## Step 3: Submitting a Job to Intel's DevCloud\n",
    "\n",
    "In the next three sub-steps, you will write your `!qsub` commands to submit your jobs to Intel's DevCloud to load your model and run inference on the **IEI Tank-870** edge node with an **Intel Core i5** CPU and an **Intel Neural Compute Stick 2** VPU.\n",
    "\n",
    "Your `!qsub` command should take the following flags and arguments:\n",
    "1. The first argument should be the shell script filename\n",
    "2. `-d` flag - This argument should be `.`\n",
    "3. `-l` flag - This argument should request an edge node with an **IEI Tank-870**. The default quantity is 1, so the **1** after `nodes` is optional. \n",
    "    * **Intel Core i5 6500TE** for your `CPU`.\n",
    "    * **Intel HD Graphics 530** for your `GPU`.\n",
    "    * **Intel Neural Compute Stick 2** for your `VPU`.\n",
    "\n",
    "To get the queue labels for these devices, you can go to [this link](https://devcloud.intel.com/edge/get_started/devcloud/)\n",
    "\n",
    "4. `-F` flag - This argument should contain the three values to assign to the variables of the shell script:\n",
    "    * **DEVICE** - Device type for the job: `CPU`,`GPU` or `MYRIAD`.\n",
    "    * **MODELPATH** - Full path to the model for the job. As a reminder, the model is located in `/data/models/intel`.\n",
    "    * **SAVEPATH** - Name of the file you want to save the performance metrics as. These should be named as the following:\n",
    "        - `cpu_stats` for the `CPU` job\n",
    "        - `vpu_stats` for the `VPU` job\n",
    "        - `gpu_stats` for the `GPU` job\n",
    "\n",
    "**Note**: There is an optional flag, `-N`, you may see in a few exercises. This is an argument that only works on Intel's DevCloud that allows you to name your job submission. This argument doesn't work in Udacity's workspace integration with Intel's DevCloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_g84tg5a"
   },
   "outputs": [],
   "source": [
    "%%writefile inference_model_job.sh\n",
    "#!/bin/bash\n",
    "\n",
    "exec 1>/output/stdout.log 2>/output/stderr.log\n",
    "\n",
    "mkdir -p /output\n",
    "\n",
    "DEVICE=$1\n",
    "MODELPATH=$2\n",
    "SAVEPATH=$3\n",
    "\n",
    "# Run the load model python script\n",
    "python3 inference_on_device.py  --model_path ${MODELPATH} --device ${DEVICE} --path ${SAVEPATH}\n",
    "\n",
    "cd /output\n",
    "\n",
    "tar zcvf output.tgz *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_2debgo3"
   },
   "source": [
    "## Step 3a: Running on the NCS2\n",
    "\n",
    "In the cell below, write the qsub command that will submit your job to the VPU (NCS2).\n",
    "\n",
    "If you get stuck, you can click on the **Show Solution** button below for a walkthrough with the solution code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "graffitiCellId": "id_6lp1qdi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tW5ubFwIhdZ6gT39CHOQ04TITSkF8MMN\n"
     ]
    }
   ],
   "source": [
    "vpu_job_id_core = !qsub inference_model_job.sh -d . -l nodes=tank-870:i5-6500te:intel-ncs2 -F \"MYRIAD /data/models/intel/vehicle-license-plate-detection-barrier-0106/FP16/vehicle-license-plate-detection-barrier-0106 vpu_stats\" -N store_core \n",
    "print(vpu_job_id_core[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_g3v8ffh"
   },
   "source": [
    "<span class=\"graffiti-highlight graffiti-id_g3v8ffh-id_bvjbx8j\"><i></i><button>Hide Solution</button></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_bvjbx8j"
   },
   "outputs": [],
   "source": [
    "vpu_job_id_core = !qsub inference_model_job.sh -d . -l nodes=tank-870:i5-6500te:intel-ncs2 -F \"MYRIAD /data/models/intel/vehicle-license-plate-detection-barrier-0106/FP16/vehicle-license-plate-detection-barrier-0106 vpu_stats\" -N store_core \n",
    "print(vpu_job_id_core[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_8nw5crc"
   },
   "source": [
    "### Check Job Status\n",
    "\n",
    "To check on the job that was submitted, use `liveQStat` to check the status of the job. The cell is locked until this finishes polling 10 times or you can interrupt the kernel to stop it by pressing the stop button at the top: ![stop button](assets/interrupt_kernel.png)\n",
    "\n",
    "Column `S` shows the state of your running jobs.\n",
    "\n",
    "For example:\n",
    "- If `JOB ID`is in Q state, it is in the queue waiting for available resources.\n",
    "- If `JOB ID` is in R state, it is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "graffitiCellId": "id_jmw0noj"
   },
   "outputs": [],
   "source": [
    "import liveQStat\n",
    "liveQStat.liveQStat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_87xg8ot"
   },
   "source": [
    "###### Get Results\n",
    "\n",
    "Run the next cell to retrieve your job's results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "graffitiCellId": "id_ohif5hf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getResults() is blocking until results of the job (id:tW5ubFwIhdZ6gT39CHOQ04TITSkF8MMN) are ready.\n",
      "Please wait...Success!\n",
      "output.tgz was downloaded in the same folder as this notebook.\n"
     ]
    }
   ],
   "source": [
    "import get_results\n",
    "\n",
    "get_results.getResults(vpu_job_id_core[0], filename=\"output.tgz\", blocking=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_x77ikbq"
   },
   "source": [
    "###### Unpack your output files and view stdout.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_0xio6td"
   },
   "outputs": [],
   "source": [
    "!tar zxf output.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_q4scme8"
   },
   "outputs": [],
   "source": [
    "!cat stdout.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_0o4s4wj"
   },
   "source": [
    "###### View stderr.log\n",
    "This can be used for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_we3k3sw"
   },
   "outputs": [],
   "source": [
    "!cat stderr.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_2debgo3"
   },
   "source": [
    "## Step 3b: Running on the CPU\n",
    "\n",
    "In the cell below, write the qsub command that will submit your job to the CPU.\n",
    "\n",
    "If you get stuck, you can click on the **Show Solution** button below for a walkthrough with the solution code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "graffitiCellId": "id_6lp1qdi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CaD0rom0jZKyWd1TrMFDtxS9UidgyzbM\n"
     ]
    }
   ],
   "source": [
    "cpu_job_id_core = !qsub inference_model_job.sh -d . -l nodes=tank-870:i5-6500te -F \"CPU /data/models/intel/vehicle-license-plate-detection-barrier-0106/FP32/vehicle-license-plate-detection-barrier-0106 cpu_stats\" -N store_core \n",
    "print(cpu_job_id_core[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_ar4zvdk"
   },
   "outputs": [],
   "source": [
    "cpu_job_id_core = !qsub inference_model_job.sh -d . -l nodes=tank-870:i5-6500te -F \"CPU /data/models/intel/vehicle-license-plate-detection-barrier-0106/FP32/vehicle-license-plate-detection-barrier-0106 cpu_stats\" -N store_core \n",
    "print(cpu_job_id_core[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_e6ujds3"
   },
   "source": [
    "<span class=\"graffiti-highlight graffiti-id_e6ujds3-id_ar4zvdk\"><i></i><button>Show Solution</button></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_8nw5crc"
   },
   "source": [
    "### Check Job Status\n",
    "\n",
    "To check on the job that was submitted, use `liveQStat` to check the status of the job. The cell is locked until this finishes polling 10 times or you can interrupt the kernel to stop it by pressing the stop button at the top: ![stop button](assets/interrupt_kernel.png)\n",
    "\n",
    "Column `S` shows the state of your running jobs.\n",
    "\n",
    "For example:\n",
    "- If `JOB ID`is in Q state, it is in the queue waiting for available resources.\n",
    "- If `JOB ID` is in R state, it is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "graffitiCellId": "id_jmw0noj"
   },
   "outputs": [],
   "source": [
    "import liveQStat\n",
    "liveQStat.liveQStat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_87xg8ot"
   },
   "source": [
    "###### Get Results\n",
    "\n",
    "Run the next cell to retrieve your job's results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "graffitiCellId": "id_ohif5hf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getResults() is blocking until results of the job (id:CaD0rom0jZKyWd1TrMFDtxS9UidgyzbM) are ready.\n",
      "Please wait.....Success!\n",
      "output.tgz was downloaded in the same folder as this notebook.\n"
     ]
    }
   ],
   "source": [
    "import get_results\n",
    "\n",
    "get_results.getResults(cpu_job_id_core[0], filename=\"output.tgz\", blocking=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_x77ikbq"
   },
   "source": [
    "###### Unpack your output files and view stdout.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_0xio6td"
   },
   "outputs": [],
   "source": [
    "!tar zxf output.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_q4scme8"
   },
   "outputs": [],
   "source": [
    "!cat stdout.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_0o4s4wj"
   },
   "source": [
    "###### View stderr.log\n",
    "This can be used for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_we3k3sw"
   },
   "outputs": [],
   "source": [
    "!cat stderr.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_2debgo3"
   },
   "source": [
    "## Step 3c: Running on the GPU\n",
    "\n",
    "In the cell below, write the qsub command that will submit your job to the GPU.\n",
    "\n",
    "If you get stuck, you can click on the **Show Solution** button below for a walkthrough with the solution code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "graffitiCellId": "id_6lp1qdi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LxxaJOlBI5UXLTF5l7V7pGBnHRdLwMOx\n"
     ]
    }
   ],
   "source": [
    "gpu_job_id_core = !qsub inference_model_job.sh -d . -l nodes=tank-870:i5-6500te:intel-hd-530 -F \"GPU /data/models/intel/vehicle-license-plate-detection-barrier-0106/FP16/vehicle-license-plate-detection-barrier-0106 gpu_stats\" -N store_core \n",
    "print(gpu_job_id_core[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_i3ywb2p"
   },
   "source": [
    "<span class=\"graffiti-highlight graffiti-id_i3ywb2p-id_wq5meiq\"><i></i><button>Hide Solution</button></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_wq5meiq"
   },
   "outputs": [],
   "source": [
    "gpu_job_id_core = !qsub inference_model_job.sh -d . -l nodes=tank-870:i5-6500te:intel-hd-530 -F \"GPU /data/models/intel/vehicle-license-plate-detection-barrier-0106/FP16/vehicle-license-plate-detection-barrier-0106 gpu_stats\" -N store_core \n",
    "print(gpu_job_id_core[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_8nw5crc"
   },
   "source": [
    "### Check Job Status\n",
    "\n",
    "To check on the job that was submitted, use `liveQStat` to check the status of the job. The cell is locked until this finishes polling 10 times or you can interrupt the kernel to stop it by pressing the stop button at the top: ![stop button](assets/interrupt_kernel.png)\n",
    "\n",
    "Column `S` shows the state of your running jobs.\n",
    "\n",
    "For example:\n",
    "- If `JOB ID`is in Q state, it is in the queue waiting for available resources.\n",
    "- If `JOB ID` is in R state, it is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "graffitiCellId": "id_jmw0noj"
   },
   "outputs": [],
   "source": [
    "import liveQStat\n",
    "liveQStat.liveQStat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_87xg8ot"
   },
   "source": [
    "###### Get Results\n",
    "\n",
    "Run the next cell to retrieve your job's results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "graffitiCellId": "id_ohif5hf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getResults() is blocking until results of the job (id:LxxaJOlBI5UXLTF5l7V7pGBnHRdLwMOx) are ready.\n",
      "Please wait...................Success!\n",
      "output.tgz was downloaded in the same folder as this notebook.\n"
     ]
    }
   ],
   "source": [
    "import get_results\n",
    "\n",
    "get_results.getResults(gpu_job_id_core[0], filename=\"output.tgz\", blocking=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_x77ikbq"
   },
   "source": [
    "###### Unpack your output files and view stdout.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_0xio6td"
   },
   "outputs": [],
   "source": [
    "!tar zxf output.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_q4scme8"
   },
   "outputs": [],
   "source": [
    "!cat stdout.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_0o4s4wj"
   },
   "source": [
    "###### View stderr.log\n",
    "This can be used for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_we3k3sw"
   },
   "outputs": [],
   "source": [
    "!cat stderr.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_il182s4"
   },
   "source": [
    "## Step 4: Plot and Compare Results\n",
    "\n",
    "Run the cell below to plot and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "graffitiCellId": "id_tbh4j28"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "graffitiCellId": "id_gxdvs1s"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: objects cannot be broadcast to a single shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-c5fe71d63ef7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vpu_stats.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gpu_stats.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cpu_stats.txt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mread_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'VPU'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'GPU'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CPU'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-c5fe71d63ef7>\u001b[0m in \u001b[0;36mread_files\u001b[0;34m(paths, labels)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mfps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Model Load Time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seconds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Inference Time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seconds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Frames per Second'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Frames'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-c5fe71d63ef7>\u001b[0m in \u001b[0;36mplot\u001b[0;34m(labels, data, title, label)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1708\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1709\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1710\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1711\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2079\u001b[0m         x, height, width, y, linewidth = np.broadcast_arrays(\n\u001b[1;32m   2080\u001b[0m             \u001b[0;31m# Make args iterable too.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2081\u001b[0;31m             np.atleast_1d(x), height, width, y, linewidth)\n\u001b[0m\u001b[1;32m   2082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morientation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'vertical'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36mbroadcast_arrays\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubok\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_broadcast_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36m_broadcast_shape\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;31m# use the old-iterator because np.nditer does not handle size 0 arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# consistently\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;31m# unfortunately, it cannot handle 32 or more arguments directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shape mismatch: objects cannot be broadcast to a single shape"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3528225c18>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot(labels, data, title, label):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    ax.set_ylabel(label)\n",
    "    ax.set_title(title)\n",
    "    ax.bar(labels, data)\n",
    "    \n",
    "def read_files(paths, labels):\n",
    "    load_time=[]\n",
    "    inference_time=[]\n",
    "    fps=[]\n",
    "    \n",
    "    for path in paths:\n",
    "        if os.path.isfile(path):\n",
    "            f=open(path, 'r')\n",
    "            load_time.append(float(f.readline()))\n",
    "            inference_time.append(float(f.readline()))\n",
    "            fps.append(float(f.readline()))\n",
    "\n",
    "    plot(labels, load_time, 'Model Load Time', 'seconds')\n",
    "    plot(labels, inference_time, 'Inference Time', 'seconds')\n",
    "    plot(labels, fps, 'Frames per Second', 'Frames')\n",
    "\n",
    "paths=['vpu_stats.txt', 'gpu_stats.txt', 'cpu_stats.txt']\n",
    "read_files(paths, ['VPU', 'GPU', 'CPU'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_5n4emve"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "graffiti": {
   "firstAuthorId": "10505542082",
   "id": "id_fqe4ya2",
   "language": "EN"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
